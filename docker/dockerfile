# syntax=docker/dockerfile:1.7-labs # at the time of this comment, only 1.7-labs version supports --exclude flag, used below.

# Use the specified NVIDIA CUDA base image
FROM nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04

# Set environment variables to prevent interactive prompts during package installations
ENV DEBIAN_FRONTEND=noninteractive

# Some official base images (like Ubuntu) include the following configuration file that automatically runs apt-get clean after installations. 
# To ensure your cache mount for /var/cache/apt/archives is effective, it's recommended to remove this file in a preceding RUN step, 
# as shown in examples in the search results
RUN rm -f /etc/apt/apt.conf.d/docker-clean

# Install dependencies needed for Miniforge installation (wget, bash)
# and clean up apt cache afterwards
RUN --mount=type=cache,target=/var/cache/apt/archives \
        apt-get update && apt-get install -y --no-install-recommends \
            wget \
            bash \
            bzip2 \
            git \
            ca-certificates \
            software-properties-common \
            && add-apt-repository ppa:deadsnakes/ppa -y \
            && apt-get update && apt-get install -y --no-install-recommends \
                python3.12 \
                python3.12-venv \
                python3.12-dev \
                python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Update alternatives to make python3.12 the default python/python3
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.12 1 \
&& update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1


# We don't use Python virtual environments. We install everything into root environment.
RUN python -m pip config set global.break-system-packages true

# Upgrade pip
#RUN python -m pip install --upgrade pip

# These are needed by Blenderproc for offscreen 3D rendering
RUN --mount=type=cache,target=/var/cache/apt/archives \
        apt-get update && apt-get install -y --no-install-recommends \
            libegl1 \
            libgl1 \
            libglx-mesa0 \
            libgles2 \
            libglvnd0 \
            libglx0 \
            xvfb \
            mesa-utils \
            libxi6 \
            libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*



# Install Python dependencies using pip
# Using a cache mount for pip cache
# Note: torch and torchvision need to be installed outside requirements.txt file, because we need to specify the --index-url in order to specify CUDA version.
# requirements.txt file grammar does not support --index-url for specific packages, only for entire file as a whole.
#RUN pip install torch torchvision xformers --index-url https://download.pytorch.org/whl/cu126
RUN pip install torch==2.3.1 torchvision==0.18.1 xformers --index-url https://download.pytorch.org/whl/cu121

# Copy the requirements file into the container
# Assumes requirements.txt is in the same directory as the Dockerfile during build
COPY SAM-6D/requirements.txt /tmp/requirements.txt

RUN --mount=type=cache,target=/root/.cache/pip \
    python -m pip install -r /tmp/requirements.txt \
    && rm /tmp/requirements.txt


###### Start of BlenderProc setup ######

# blenderproc 2.8.0 is having difficulty downloading Blender 4.2.1 from the following URL on its own.
# Let us download it ourselves instead, and then make blenderproc use a custom Blender installation
# path at runtime. E.g.:
# $> blenderproc run --custom-blender-path $BLENDER_PATH render_custom_templates.py --output_dir /Data/output --cad_path /Data/Example/obj_000005.ply
# Define a target dir for the cache mount
ARG BLENDER_CACHE_DIR=/cache/blender_download
ARG BLENDER_NAME=blender-4.2.1-linux-x64
ARG BLENDER_URL=https://download.blender.org/release/Blender4.2/${BLENDER_NAME}.tar.xz
ENV BLENDER_PATH=/${BLENDER_NAME}

RUN --mount=type=cache,id=blender-download-cache,target=${BLENDER_CACHE_DIR} \
    wget -nc -P ${BLENDER_CACHE_DIR} ${BLENDER_URL} && \
    mkdir -p ${BLENDER_PATH} && \
    tar -xf ${BLENDER_CACHE_DIR}/${BLENDER_NAME}.tar.xz
    # rm blender-4.2.1-linux-x64.tar.xz # do not remove the downloaded file, leave it in the Docker's mount cache!

##### End of BlenderProc setup ######

# Copy application code
# Leave the run_inference_custom scripts to the very end because they are expected to change a lot during development
# and we want to avoid re-running all these Docker layers that follow...
COPY SAM-6D/Render /SAM-6D/Render
COPY --exclude=run_inference_custom.py SAM-6D/Instance_Segmentation_Model /SAM-6D/Instance_Segmentation_Model
COPY --exclude=run_inference_custom.py SAM-6D/Pose_Estimation_Model /SAM-6D/Pose_Estimation_Model


# We must run render with BlenderProc at least once, because during first usage, 
# it will create its own Python environment and download several packages from the Internet.
COPY ./SAM-6D/Data/Example/ /SAM-6D/Render/Example
RUN cd /SAM-6D/Render && blenderproc run --custom-blender-path $BLENDER_PATH \
    render_custom_templates.py --output_dir . \
    --cad_path /SAM-6D/Render/Example/obj_000005.ply && \
    rm -rf templates Example


# PointNet2 setup
# Targeting following GPUs: L4 and RTX 4060.
# Both are based on the Ada Lovelace architecture, with CUDA compute capability 8.9
ENV TORCH_CUDA_ARCH_LIST="8.9"
RUN cd /SAM-6D/Pose_Estimation_Model/model/pointnet2 && python setup.py install


# Copy the 4 PyTorch models used by SAM-6D
COPY ./SAM-6D/Models/dinov2_vitl14_pretrain.pth /SAM-6D/Instance_Segmentation_Model/checkpoints/dinov2/dinov2_vitl14_pretrain.pth
COPY ./SAM-6D/Models/FastSAM-x.pt               /SAM-6D/Instance_Segmentation_Model/checkpoints/FastSAM/FastSAM-x.pt
COPY ./SAM-6D/Models/sam_vit_h_4b8939.pth       /SAM-6D/Instance_Segmentation_Model/checkpoints/segment-anything/sam_vit_h_4b8939.pth
COPY ./SAM-6D/Models/sam-6d-pem-base.pth        /SAM-6D/Pose_Estimation_Model/checkpoints/sam-6d-pem-base.pth
COPY ./SAM-6D/Models/mae_pretrain_vit_base.pth  /SAM-6D/Pose_Estimation_Model/checkpoints/mae_pretrain_vit_base.pth

# Copy the demo scripts
COPY SAM-6D/demo.sh /SAM-6D/demo.sh
COPY SAM-6D/demo.py /SAM-6D/demo.py
COPY SAM-6D/ipdreader.py /SAM-6D/ipdreader.py
COPY SAM-6D/runtime_utils.py /SAM-6D/runtime_utils.py

# Copy the two run_inference_custom.py files that we excluded earlier.
COPY SAM-6D/Instance_Segmentation_Model/run_inference_custom.py /SAM-6D/Instance_Segmentation_Model/run_inference_custom.py
COPY SAM-6D/Pose_Estimation_Model/run_inference_custom.py /SAM-6D/Pose_Estimation_Model/run_inference_custom.py

# Set default command. Choose one:
#CMD ["/bin/bash"]
#CMD ["/bin/bash", "-c", "cd /SAM-6D && bash demo.sh"]
CMD ["/bin/bash", "-c", "cd /SAM-6D && python demo.py"]
